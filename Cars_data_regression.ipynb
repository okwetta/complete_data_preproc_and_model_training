{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-7v8M4jOLUw"
   },
   "source": [
    "# Загрузка и первичный анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6rD9_RiOHDB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "\n",
    "from urllib.parse import urlencode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KrIgIZ9Dbeme"
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZOdHmniy8zT"
   },
   "outputs": [],
   "source": [
    "TEST = \"https://www.dropbox.com/s/asf4b1z1yme5o7u/cars_test.csv?dl=1\"\n",
    "TRAIN = \"https://www.dropbox.com/s/qk4b79i7c078sxm/cars_train.csv?dl=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C6JzzceFxvM3"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZTy_bFA7h7Ol",
    "outputId": "6409d995-66ac-481b-a7ae-5a3f60c3a431"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3UrzHma2RXy"
   },
   "source": [
    "Выделим целевую переменную `sellingprice` в отдельную переменную `y`, а `X` - матрица объект-признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMVKr2PW0sFN"
   },
   "outputs": [],
   "source": [
    "X = data.drop('sellingprice', axis=1)\n",
    "y = data['sellingprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "IJnCxCpS2ed_",
    "outputId": "ac7a5d45-059a-4572-cb85-adfc94f8afc2"
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsilSlNN2kwN"
   },
   "source": [
    "Посмотрим на типы колонок и число пропущенных значений в них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D1alFgkU2oZX",
    "outputId": "884edede-bcf6-4b0c-9d35-4ec8a6f44447"
   },
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZWuwqYE3YM6"
   },
   "source": [
    "Посмотрим на числовые признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "qe_e9hnI2_t7",
    "outputId": "99aecbbe-64aa-4944-ac62-a8d0d967093d"
   },
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYpFqj2X3bXv"
   },
   "source": [
    "Посмотрим на категориальные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "Ub1rZwdA3dci",
    "outputId": "bca240ca-dad0-4695-f0bd-99e607826715"
   },
   "outputs": [],
   "source": [
    "X.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1iL9nHu4tQT"
   },
   "source": [
    "Признак `vin` это уникальный идентификатор машины, поэтому удалим его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcLqDLeG4y6T"
   },
   "outputs": [],
   "source": [
    "X.drop('vin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-7v8M4jOLUw",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Разведочный анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним пропуски в числовых столбцах средним значением, а в категориальных - пустой категорией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X.columns:\n",
    "    if X[i].dtype == 'object':\n",
    "          X[i].fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X.columns:\n",
    "    if X[i].dtype != 'object':\n",
    "          mean = np.mean(X[i])\n",
    "          X[i].fillna(mean, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка категориальных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на количество значений в каждой категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in X.columns:\n",
    "    if X[c].dtype == 'object':\n",
    "          print(c, len(X[c].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В saledate очень много различных значений. Обработаем saledate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['car_age'] = X['saledate'].apply(lambda x: int(x.split(\" \")[3])) - X['year']\n",
    "X['date'] = X['saledate'].apply(lambda x: x.split(\" \")[1]+x.split(\" \")[3])\n",
    "\n",
    "X.drop('saledate', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Корреляционные матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "\n",
    "X['target'] = y\n",
    "\n",
    "cols = X.columns[X.dtypes != 'object']\n",
    "\n",
    "corr = X[cols].corr()\n",
    "sb.heatmap(corr, cmap=\"Blues\", annot=True)\n",
    "\n",
    "X.drop('target', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все числовые признаки важны. Посмотрим на аналог корреляции категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import association_metrics as am\n",
    "\n",
    "XC = X.apply(\n",
    "        lambda x: x.astype(\"category\") if x.dtype == \"object\" else x)\n",
    "\n",
    "cramersv = am.CramersV(XC)\n",
    "\n",
    "cramersv.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки make и model сильно связаны, поэтому уберем make как менее информативный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop('make', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим влияние категориального признака на целевую переменную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.scatterplot(data=X.iloc[:100], x=X.iloc[:100].index, y=y[:100], hue='date');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=X.iloc[:100], x=X.iloc[:100].index, y=y[:100], hue='interior');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=X.iloc[:100], x=X.iloc[:100].index, y=y[:100], hue='transmission');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y, bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск аномальных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = X.columns[X.dtypes == 'object']\n",
    "num_cols = X.columns[X.dtypes != 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    print(col)\n",
    "    sb.boxplot(X[col])\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X['odometer'] > 800000][['car_age','odometer']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выкинем машины младше 10 лет, проехавшие 1000000 миль - это почти точно выбросы. Удалим car_age, так как в дате есть столбец yaer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = X[~((X.car_age < 10) & (X.odometer > 800_000))]\n",
    "ynew = y[~((X.car_age < 10) & (X.odometer > 800_000))]\n",
    "\n",
    "Xnew.drop('car_age', axis=1, inplace=True);\n",
    "print(Xnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Построение baseline-модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для baseline-модели:\n",
    "1) закодируем категориальные признаки при помощи TargetEncoder\n",
    "2) масштабируем все признаки с помощью StandardScaler\n",
    "3) обучим линейную регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from category_encoders.leave_one_out import LeaveOneOutEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xnew, ynew, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "enc = TargetEncoder(cols=cat_cols)\n",
    "enc.fit(X_train, y_train)\n",
    "X_train_new = enc.transform(X_train)\n",
    "X_test_new = enc.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_new)\n",
    "X_train_new = pd.DataFrame(scaler.transform(X_train_new), columns=X_train.columns)\n",
    "X_test_new = pd.DataFrame(scaler.transform(X_test_new), columns=X_test.columns)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_new, y_train)\n",
    "pred = model.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error as MAPE\n",
    "\n",
    "MAPE(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "p1 = Pipeline([\n",
    "    ('encoder_',TargetEncoder(cols=cat_cols)),\n",
    "    ('scaler_', StandardScaler()),\n",
    "    ('model_', LinearRegression())\n",
    "    ])\n",
    "p2 = Pipeline([\n",
    "    ('encoder_',TargetEncoder(cols=cat_cols, smoothing=1)),\n",
    "    ('scaler_', StandardScaler()),\n",
    "    ('model_', LinearRegression())\n",
    "    ])\n",
    "\n",
    "p3 = Pipeline([\n",
    "    ('encoder_',TargetEncoder(cols=cat_cols, smoothing=100)),\n",
    "    ('scaler_', StandardScaler()),\n",
    "    ('model_', LinearRegression())\n",
    "    ])\n",
    "\n",
    "p4 = Pipeline([\n",
    "    ('encoder_',TargetEncoder(cols=cat_cols, smoothing=1)),\n",
    "    ('scaler_', MinMaxScaler()),\n",
    "    ('model_', LinearRegression())\n",
    "    ])\n",
    "\n",
    "p5 = Pipeline([\n",
    "    ('encoder_',TargetEncoder(cols=cat_cols, smoothing=10)),\n",
    "    ('scaler_', MinMaxScaler()),\n",
    "    ('model_', LinearRegression())\n",
    "    ])\n",
    "\n",
    "p6 = Pipeline([\n",
    "    ('encoder_',TargetEncoder(cols=cat_cols, smoothing=100)),\n",
    "    ('scaler_', MinMaxScaler()),\n",
    "    ('model_', LinearRegression())\n",
    "    ])\n",
    "\n",
    "p7 = Pipeline([\n",
    "    ('encoder_',LeaveOneOutEncoder(cols=cat_cols)),\n",
    "    ('scaler_', StandardScaler()),\n",
    "    ('model_', LinearRegression())\n",
    "    ])\n",
    "\n",
    "p8 = Pipeline([\n",
    "    ('encoder_',LeaveOneOutEncoder(cols=cat_cols)),\n",
    "    ('scaler_', MinMaxScaler()),\n",
    "    ('model_', LinearRegression())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,p in enumerate([p1,p2,p3,p4,p5,p6,p7,p8]):\n",
    "    p.fit(X_train, y_train)\n",
    "    pred = p.predict(X_test)\n",
    "    print(i+1, MAPE(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодировка и масштабирование не улучшили модель, сменим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p9 = Pipeline([\n",
    "    ('encoder_',TargetEncoder(cols=cat_cols)),\n",
    "    ('scaler_', StandardScaler()),\n",
    "    ('model_', RandomForestRegressor(n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "p9.fit(X_train, y_train)\n",
    "pred = p9.predict(X_test)\n",
    "MAPE(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем для RandomForest поменять кодировщик, его гиперпараметры и скалер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p10 = Pipeline([\n",
    "    ('encoder_',LeaveOneOutEncoder(cols=cat_cols)),\n",
    "    ('scaler_', StandardScaler()),\n",
    "    ('model_', RandomForestRegressor(n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "p11 = Pipeline([\n",
    "    ('encoder_',TargetEncoder(cols=cat_cols)),\n",
    "    ('scaler_', MinMaxScaler()),\n",
    "    ('model_', RandomForestRegressor(n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "p12 = Pipeline([\n",
    "    ('encoder_',LeaveOneOutEncoder(cols=cat_cols)),\n",
    "    ('scaler_', MinMaxScaler()),\n",
    "    ('model_', RandomForestRegressor(n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "p13 = Pipeline([\n",
    "    ('encoder_',TargetEncoder(cols=cat_cols, smoothing=1)),\n",
    "    ('scaler_', StandardScaler()),\n",
    "    ('model_', RandomForestRegressor(n_jobs=-1))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,p in enumerate([p9,p10,p11,p12,p13]):\n",
    "    p.fit(X_train.iloc[:50000], y_train[:50000])\n",
    "    pred = p.predict(X_test)\n",
    "    print(i+9, MAPE(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p9.fit(X_train, y_train)\n",
    "pred = p9.predict(X_test)\n",
    "MAPE(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на важность признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.DataFrame(p9['model_'].feature_importances_, index=X_train.columns).sort_values(by=0, ascending=False)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Попытки улучшить модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y, bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сделать распределение целевой переменной более похожим на нормальное и заново обучить лучшую модель с предыдущего шага."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log(y), bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p9 = Pipeline([\n",
    "    ('encoder_',TargetEncoder(cols=cat_cols)),\n",
    "    ('scaler_', StandardScaler()),\n",
    "    ('model_', RandomForestRegressor(n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "p9.fit(X_train, y_train)\n",
    "pred = p9.predict(X_test)\n",
    "\n",
    "MAPE(np.exp(y_test), np.exp(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразование целевой переменной улучшило качество модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipeline = Pipeline([\n",
    "        ('encoder_',TargetEncoder(cols=cat_cols)),\n",
    "        ('scaler_', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train_good = data_pipeline.fit_transform(X_train, y_train)\n",
    "X_test_good = data_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    param = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 1000),\n",
    "        \"max_features\": trial.suggest_categorical(\"max_features\", ['sqrt', 'log2', None])\n",
    "    }\n",
    "\n",
    "    estimator = RandomForestRegressor(**param, verbose=False, n_jobs=-1)\n",
    "\n",
    "    estimator.fit(X_train_good[:50000], y_train.iloc[:50000])\n",
    "    pred = estimator.predict(X_test_good)\n",
    "\n",
    "    return MAPE(np.exp(y_test), np.exp(pred))\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=15)\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=745, n_jobs=-1)\n",
    "\n",
    "model.fit(X_train_good, y_train)\n",
    "pred = model.predict(X_test_good)\n",
    "MAPE(np.exp(y_test), np.exp(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая модель сейчас RandomForest\n",
    "\n",
    "Попробуем CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "model = CatBoostRegressor()\n",
    "\n",
    "model.fit(X_train_good, y_train)\n",
    "pred = model.predict(X_test_good)\n",
    "\n",
    "MAPE(np.exp(y_test), np.exp(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем гиперпараметры буста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    param = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 16),\n",
    "    }\n",
    "\n",
    "    estimator = CatBoostRegressor(**param, verbose=False)\n",
    "\n",
    "    estimator.fit(X_train_good[:50000], y_train.iloc[:50000])\n",
    "    pred = estimator.predict(X_test_good)\n",
    "\n",
    "    return MAPE(np.exp(y_test), np.exp(pred))\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=15)\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(n_estimators=477, max_depth=11)\n",
    "\n",
    "model.fit(X_train_good, y_train)\n",
    "pred_cb = model.predict(X_test_good)\n",
    "\n",
    "MAPE(np.exp(y_test), np.exp(pred_cb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть CatBoost сам закодирует признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [1,2,3,4,5,8,9,10,11]\n",
    "\n",
    "model = CatBoostRegressor(cat_features=cat_features)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "MAPE(np.exp(y_test), np.exp(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Stacking и Blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Простое смешивание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RandomForest - 0.178\n",
    "* CatBoost - 0.170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_final = 0.3 * pred + 0.7 * pred_cb\n",
    "\n",
    "MAPE(np.exp(y_test), np.exp(pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking и blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestRegressor(n_jobs=-1)),\n",
    "    ('cb', CatBoostRegressor(n_estimators=477, max_depth=11))\n",
    "    ]\n",
    "\n",
    "reg = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RandomForestRegressor(n_estimators=10, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train_good, y_train)\n",
    "pred_stacking = reg.predict(X_test_good)\n",
    "\n",
    "MAPE(np.exp(y_test), np.exp(pred_stacking))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Сохранение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполняем пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in test_data.columns:\n",
    "    if test_data[c].dtype == 'object':\n",
    "          test_data[c].fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in test_data.columns:\n",
    "    if test_data[c].dtype != 'object':\n",
    "          mean = np.mean(X[c])\n",
    "          test_data[c].fillna(mean, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обрабатываем дату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['date'] = test_data['saledate'].apply(lambda x: x.split(\" \")[1]+x.split(\" \")[3])\n",
    "test_data.drop(['vin','make','saledate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_good = data_pipeline.transform(test_data)\n",
    "test_pred = reg.predict(test_good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем предсказания в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['prediction'] = test_pred\n",
    "\n",
    "test_data[['prediction']].to_csv(\"test_prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохраним модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "    \n",
    "'''\n",
    " А так модель можно загрузить из файла:\n",
    "with open('filename.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
